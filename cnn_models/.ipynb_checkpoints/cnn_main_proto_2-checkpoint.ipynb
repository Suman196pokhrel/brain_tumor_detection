{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9686a6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-12 17:18:15.437071: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/suman/.pyenv/versions/3.9.5/envs/mlENV/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-02-12 17:18:15.437104: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import normalize\n",
    "from keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a28a8c3",
   "metadata": {},
   "source": [
    "# Loading image data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6636c084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 1500\n"
     ]
    }
   ],
   "source": [
    "img_dir = '../data/'\n",
    "no_tumor = os.listdir(img_dir + 'no/')\n",
    "yes_tumor = os.listdir(img_dir + 'yes/')\n",
    "dataset = []\n",
    "label = []\n",
    "input_size = 64\n",
    "print(len(no_tumor), len(yes_tumor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b2db8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i , image_name in enumerate(no_tumor):\n",
    "    if(image_name.split('.')[1]=='jpg'):\n",
    "        image=cv2.imread(img_dir+'no/'+image_name)\n",
    "        image=Image.fromarray(image,'RGB')\n",
    "        image=image.resize((input_size,input_size))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(0)\n",
    "\n",
    "for i , image_name in enumerate(yes_tumor):\n",
    "    if(image_name.split('.')[1]=='jpg'):\n",
    "        image=cv2.imread(img_dir+'yes/'+image_name)\n",
    "        image=Image.fromarray(image, 'RGB')\n",
    "        image=image.resize((input_size,input_size))\n",
    "        dataset.append(np.array(image))\n",
    "        label.append(1)\n",
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b211d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=np.array(dataset)\n",
    "label=np.array(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f0e87d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df = pd.Series(label)\n",
    "label_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e978653d",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2119df36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter \n",
    "# counts the number of occures of each label and save them in a dictionary\n",
    "c = Counter(label)\n",
    "#rename the keys and delete the old one\n",
    "c[\"Healthy\"] = c[0]\n",
    "del c[0]\n",
    "c['Tumor'] = c[1]\n",
    "del c[1]\n",
    "#plot each key and value in c \n",
    "plot=plt.bar(c.keys(), c.values())\n",
    "plot[0].set_color('darkgreen')\n",
    "plot[1].set_color('darkorange')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb45e352",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6432258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test=train_test_split(dataset, label, test_size=0.2, random_state=0)\n",
    "x_train=normalize(x_train,axis=1)\n",
    "x_test=normalize(x_test,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ae3863",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0323edda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-12 17:18:26.776349: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/suman/.pyenv/versions/3.9.5/envs/mlENV/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-02-12 17:18:26.776371: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-02-12 17:18:26.776389: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (archSuman): /proc/driver/nvidia/version does not exist\n",
      "2022-02-12 17:18:26.776570: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"conv2d_4\" (type Conv2D).\n\nNegative dimension size caused by subtracting 3 from 2 for '{{node conv2d_4/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_4/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,32], [3,3,32,32].\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 2, 2, 32), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mMaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# # # 5th conv2D layer\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mkernel_initializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhe_uniform\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mActivation(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     25\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mMaxPooling2D(pool_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)))\n",
      "File \u001b[0;32m~/.pyenv/versions/mlENV/lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py:530\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 530\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/mlENV/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/mlENV/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1939\u001b[0m, in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1936\u001b[0m   c_op \u001b[38;5;241m=\u001b[39m pywrap_tf_session\u001b[38;5;241m.\u001b[39mTF_FinishOperation(op_desc)\n\u001b[1;32m   1937\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1938\u001b[0m   \u001b[38;5;66;03m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m-> 1939\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(e\u001b[38;5;241m.\u001b[39mmessage)\n\u001b[1;32m   1941\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m c_op\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"conv2d_4\" (type Conv2D).\n\nNegative dimension size caused by subtracting 3 from 2 for '{{node conv2d_4/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_4/Conv2D/ReadVariableOp)' with input shapes: [?,2,2,32], [3,3,32,32].\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 2, 2, 32), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model=models.Sequential()\n",
    "# 1st conv2D layer\n",
    "model.add(layers.Conv2D(32,(3,3),input_shape=(input_size,input_size,3)))\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# # 2nd conv2D layer\n",
    "model.add(layers.Conv2D(32,(3,3),kernel_initializer='he_uniform'))\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# # 3rd conv2D layer\n",
    "model.add(layers.Conv2D(32,(3,3),kernel_initializer='he_uniform'))\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# # 4th conv2D layer\n",
    "model.add(layers.Conv2D(32,(3,3),kernel_initializer='he_uniform'))\n",
    "model.add(layers.Activation(\"relu\"))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# # # # 5th conv2D layer\n",
    "# model.add(layers.Conv2D(32,(3,3),kernel_initializer='he_uniform'))\n",
    "# model.add(layers.Activation(\"relu\"))\n",
    "# model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# # # 6th conv2D layer\n",
    "# model.add(layers.Conv2D(32,(3,3),kernel_initializer='he_uniform'))\n",
    "# model.add(layers.Activation(\"relu\"))\n",
    "# model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(input_size))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1))\n",
    "model.add(layers.Activation('sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2b4521",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model,\n",
    "                          to_file=\"model.png\",\n",
    "                          show_shapes=True,\n",
    "                          expand_nested=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f039f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_plot(tr_data, start_epoch):\n",
    "    #Plot the loss and accuracy curve\n",
    "    tacc=tr_data.history['accuracy']\n",
    "    tloss=tr_data.history['loss']\n",
    "    vacc=tr_data.history['val_accuracy']\n",
    "    vloss=tr_data.history['val_loss']\n",
    "    Epoch_count=len(tacc)+ start_epoch\n",
    "    Epochs=[]\n",
    "    for i in range (start_epoch ,Epoch_count):\n",
    "        Epochs.append(i+1)\n",
    "    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n",
    "    val_lowest=vloss[index_loss]\n",
    "    index_acc=np.argmax(vacc)\n",
    "    acc_highest=vacc[index_acc]\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n",
    "    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n",
    "    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n",
    "    axes[0].plot(Epochs,tloss, 'orange', label='Training loss')\n",
    "    axes[0].plot(Epochs,vloss,'blue',label='Validation loss' )\n",
    "    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n",
    "    axes[0].set_title('Training and Validation Loss')\n",
    "    axes[0].set_xlabel('Epochs')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].legend()\n",
    "    axes[1].plot (Epochs,tacc,'orange',label= 'Training Accuracy')\n",
    "    axes[1].plot (Epochs,vacc,'blue',label= 'Validation Accuracy')\n",
    "    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n",
    "    axes[1].set_title('Training and Validation Accuracy')\n",
    "    axes[1].set_xlabel('Epochs')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].legend()\n",
    "    plt.tight_layout\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c1301d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history=model.fit(x_train,y_train,batch_size=16,verbose=1,epochs=17\n",
    "          , validation_data=(x_test,y_test),\n",
    "          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ba460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the history\n",
    "tr_plot(history,0)\n",
    "model.save('BrainTumorDetection_model_3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e36ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"BrainTumorDetection_model_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20124f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = []\n",
    "\n",
    "image_test = cv2.imread(\"../data/archive/yes/Y1.jpg\") \n",
    "image_test = Image.fromarray(image_test, 'RGB')\n",
    "image_test = image_test.resize((input_size,input_size))\n",
    "pred_data.append(np.array(image_test))\n",
    "pred = np.asarray(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32899fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
